{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOMEDIN 260/RAD260: Problem Set 3 - Mammogram Project\n",
    "\n",
    "## Spring 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name 1:\n",
    "\n",
    "Aaron Sossin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name 2:\n",
    "\n",
    "Vivian Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Breast cancer has the highest incidence and second highest mortality rate for women in the US.\n",
    "\n",
    "Your task is to utilize machine learning to study mammograms in any way you want (e.g. classification, segmentation) as long as you justify why it is useful to do whatever it is you want to do. Turning in a deep dream assignment using mammograms might be amusing, for example, but not so useful to patients. That being said, choose something that interests you. As the adage goes, \"do what you love, and you’ll never have to work another day in your life, at least in BMI 260.\"\n",
    "\n",
    "Treat this as a mini-project. We highly encourage working with 1 other person, possibly someone in your main project team. \n",
    "\n",
    "In addition to the mammograms themselves, the dataset includes \"ground-truth\" segmentations and `mass_case_description_train_set.csv`, which contains metadata information about mass shapes, mass margins, assessment numbers, pathology diagnoses, and subtlety in the data. Take some time to research what all of these different fields mean and how you might utilize them in your work. You dont need to use all of what is provided to you.\n",
    "\n",
    "Some ideas:\n",
    "\n",
    "1. Use the ROI’s or segmentations to extract features, and then train a classifier based on those features using the algorithms presented to you in the machine learning lectures (doesn't need to use deep learning).\n",
    "\n",
    "2. Use convolutional neural networks. Feel free to use any of the code we went over in class or use your own (custom code, sklearn, keras, Tensorflow etc.). If you dont want to place helper functions and classes into this notebook, place them in a `.py` file in the same folder called `helperfunctions.py` and import them into this notebook.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data is here:\n",
    "\n",
    "https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM\n",
    "\n",
    "## Grading and Submission\n",
    "\n",
    "This assignment has 3 components: code, figures (outputs/analyses of your code), and a write-up detailing your mini-project. You will be graded on these categories.\n",
    "\n",
    "If you're OK with Python or R, please place all three parts into this notebook/.Rmd file that we have provided where indicated. We have written template sections for you to follow for simplicity/completeness. When you're done, save as a `.pdf` (please knit to `.pdf` if you are using `.Rmd`, or knit to `.html` and use a browser's \"Print\" function to convert to `.pdf`).\n",
    "\n",
    "If you don't like Python OR R, we will allow you to use a different language, but please turn your assignment in with: 1) a folder with all your code, 2) a folder with all your figures, and 3) a `.tex`/`.doc`/`.pdf` file with a write-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT TITLE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Describe what you are doing and why it matters to patients using at least one citation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast cancer is one of the most common cancer in women worldwide. \n",
    "\n",
    "We will have use two approaches of deep learning in this project: \n",
    "\n",
    "In the first approach, we plan to use the mammograms images and its masks to predict whether the tumor is benign or not. We plan to utilize a classic convolutional neural network to take the two images as inputs and return the diagnosis as a one dimensional vector. This image based method could be promising for helping doctors to identify patients with tumors. we can also use it to double check doctor's diagnosis result. \n",
    "\n",
    "\n",
    "In the second approach, we plan to use the mamogram images to predict its corresponding mask. We will be using both convolutional neural networks and U-nets to do this image segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Describe the relevant statistics of the data. How were the images taken? How were they labeled? What is the class balance and majority classifier accuracy? How will you divide the data into testing, training and validation sets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first approach, our data consists of breast X-ray scan mammograms and their masks. It includes the patient's left and right side in both the craniocaudal and mediolateral oblique views. They are labeled by doctors as malignant, benign, and benign_without_callback. \n",
    "\n",
    "For the second approach, the input data is the mammogram scan image and the output image is the mask image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SPACE FOR CODE FOR QUESTION 2 HERE, SHOULD YOU NEED IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage\n",
    "import sys\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv3D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, UpSampling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras import Sequential\n",
    "import cv2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach: using images to predict whether the outcome is malignant or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "file_root = \"data\"\n",
    "case = pd.read_csv(\"mass_case_description_train_set.csv\")\n",
    "def get_data(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    path_contents = os.walk(path)\n",
    "    for root, directories, files in path_contents: \n",
    "        for file in files:\n",
    "            if (file.split(\".\")[1] == \"h5\"):\n",
    "                path = root + '/' + file\n",
    "                h5 = h5py.File(path, 'r')\n",
    "                \n",
    "\n",
    "                patient_id = \"P_\" + root.split(\"/\")[1]\n",
    "                side = file.split(\".\")[0].split(\"_\")[0]\n",
    "                view = file.split(\".\")[0].split(\"_\")[1]\n",
    "                pathology = case[(case.patient_id == patient_id) & (case.side == side) & (case.view == view) ][\"pathology\"]\n",
    "                if (len(pathology.tolist())>0):\n",
    "                    X.append(h5['data'])\n",
    "                    pathology = pathology.tolist()[0]\n",
    "                    y.append(pathology)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def normalize_data(x, y):\n",
    "    x -= x.mean(axis=(1, 2), keepdims=True)\n",
    "    x /= x.std(axis=(1, 2), keepdims=True)\n",
    "    encoder = LabelBinarizer()\n",
    "    transformed_label = encoder.fit(np.unique(y).tolist())\n",
    "    y = transformed_label.transform(y.tolist())\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_data(file_root)\n",
    "X, y = normalize_data(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(256,256,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 252, 252, 16)      816       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 122, 122, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 57, 57, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,355,603\n",
      "Trainable params: 1,355,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 20s 2s/step - loss: 0.6522 - accuracy: 0.4454 - val_loss: 0.5845 - val_accuracy: 0.5345\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.6298 - accuracy: 0.4973 - val_loss: 0.5926 - val_accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.5756 - accuracy: 0.5156 - val_loss: 0.6208 - val_accuracy: 0.5345\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.5663 - accuracy: 0.5095 - val_loss: 0.6184 - val_accuracy: 0.5345\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.5761 - accuracy: 0.5275 - val_loss: 0.5626 - val_accuracy: 0.5345\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.5476 - accuracy: 0.5308 - val_loss: 0.5926 - val_accuracy: 0.5345\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.5559 - accuracy: 0.5430 - val_loss: 0.5774 - val_accuracy: 0.5345\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.5823 - accuracy: 0.4761 - val_loss: 0.5608 - val_accuracy: 0.5345\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.5625 - accuracy: 0.5209 - val_loss: 0.5490 - val_accuracy: 0.5345\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.5619 - accuracy: 0.5306 - val_loss: 0.5356 - val_accuracy: 0.5345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f334d329e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_1()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second approach: Predicting masks from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filename = \"data/00051/LEFT_CC.h5\"\n",
    "# h5 = h5py.File(filename, 'r')\n",
    "# data= h5['data']\n",
    "# label = h5['label']\n",
    "# name = h5['name']\n",
    "# X = data[:, :, 0]\n",
    "# X2 = np.reshape(X, (256, 256, 1))\n",
    "\n",
    "# X = cv2.merge((X, X, X))\n",
    "# y = data[:, :, 1]\n",
    "# plt.imshow(X)\n",
    "# plt.show()\n",
    "# plt.imshow(y)\n",
    "# plt.show()\n",
    "# y = np.reshape(y, (256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "file_root = \"data\"\n",
    "\n",
    "def get_data(path):\n",
    "    patients = list()\n",
    "    left = list()\n",
    "    right = list()\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    path_contents = os.walk(path)\n",
    "    for root, directories, files in path_contents: \n",
    "        for file in files:\n",
    "            if (file.split(\".\")[1] == \"h5\"):\n",
    "                path = root + '/' + file\n",
    "                h5 = h5py.File(path, 'r')\n",
    "                data= h5['data']\n",
    "                temp = data[:, :, 0]\n",
    "                temp = cv2.merge((temp, temp, temp))\n",
    "                X.append(temp)\n",
    "                y.append(data[:, :, 1].reshape(256, 256, 1))\n",
    "#             patients.append(file)\n",
    "            \n",
    "#             if file[0:4] == \"LEFT\":\n",
    "#                 left.append('/'.join((path, file)))\n",
    "#             elif file[0:5] == \"RIGHT\":\n",
    "#                 right.append('/'.join((path, file)))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_data(file_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model functions\n",
    "\n",
    "def model_3Layer_2D(learning_rate):\n",
    "    X_input = Input((256, 256,3))\n",
    "    X = BatchNormalization(name='bn0')(X_input)\n",
    "    X = Conv2D(30, (1, 1), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(name='bn1')(X)\n",
    "    X = Conv2D(10, (1, 1), strides=(1, 1), name='conv1')(X)\n",
    "    X = BatchNormalization(name='bn2')(X)\n",
    "    X = Conv2D(1, (1,1), strides=(1,1), name='conv2')(X)\n",
    "    model = Model(inputs=X_input, outputs=X, name='TwoLayer')\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='accuracy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_3Layer_2D(0.001)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=3, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 2 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Describe your data pipeline (how is the data scrubbed, normalized, stored, and fed to the model for training?).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data were "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Explain how the model you chose works alongside the code for it. Add at least one technical citation to give credit where credit is due.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE FOR QUESTION 4 HERE. USE ADDITIONAL CODE/MARKDOWN CELLS IF NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 4 HERE. USE ADDITIONAL CODE/MARKDOWN CELLS IF NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. There are many ways to do training. Take us through how you do it (e.g. \"We used early stopping and stopped when validation loss increased twice in a row.\").**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 5 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Make a figure displaying your results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE FOR QUESTION 6 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 6 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Discuss pros and cons of your method and what you might have done differently now that you've tried or would try if you had more time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 7 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will not be graded on the performance of your model. You'll only be graded on the scientific soundness of your claims, methodology, evaluation (i.e. fair but insightful statistics), and discussion of the strengths and shortcomings of what you tried. Feel free to reuse some of the code you are/will be using for your projects. The write-up doesn't need to be long (~1 page will suffice), but please cite at least one clinical paper and one technical paper (1 each in questions 1 and 4 at least, and more if needed).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
