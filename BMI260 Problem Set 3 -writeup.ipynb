{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOMEDIN 260/RAD260: Problem Set 3 - Mammogram Project\n",
    "\n",
    "## Spring 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name 1:\n",
    "\n",
    "Aaron Sossin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name 2:\n",
    "\n",
    "Vivian Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Breast cancer has the highest incidence and second highest mortality rate for women in the US.\n",
    "\n",
    "Your task is to utilize machine learning to study mammograms in any way you want (e.g. classification, segmentation) as long as you justify why it is useful to do whatever it is you want to do. Turning in a deep dream assignment using mammograms might be amusing, for example, but not so useful to patients. That being said, choose something that interests you. As the adage goes, \"do what you love, and you’ll never have to work another day in your life, at least in BMI 260.\"\n",
    "\n",
    "Treat this as a mini-project. We highly encourage working with 1 other person, possibly someone in your main project team. \n",
    "\n",
    "In addition to the mammograms themselves, the dataset includes \"ground-truth\" segmentations and `mass_case_description_train_set.csv`, which contains metadata information about mass shapes, mass margins, assessment numbers, pathology diagnoses, and subtlety in the data. Take some time to research what all of these different fields mean and how you might utilize them in your work. You dont need to use all of what is provided to you.\n",
    "\n",
    "Some ideas:\n",
    "\n",
    "1. Use the ROI’s or segmentations to extract features, and then train a classifier based on those features using the algorithms presented to you in the machine learning lectures (doesn't need to use deep learning).\n",
    "\n",
    "2. Use convolutional neural networks. Feel free to use any of the code we went over in class or use your own (custom code, sklearn, keras, Tensorflow etc.). If you dont want to place helper functions and classes into this notebook, place them in a `.py` file in the same folder called `helperfunctions.py` and import them into this notebook.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data is here:\n",
    "\n",
    "https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM\n",
    "\n",
    "## Grading and Submission\n",
    "\n",
    "This assignment has 3 components: code, figures (outputs/analyses of your code), and a write-up detailing your mini-project. You will be graded on these categories.\n",
    "\n",
    "If you're OK with Python or R, please place all three parts into this notebook/.Rmd file that we have provided where indicated. We have written template sections for you to follow for simplicity/completeness. When you're done, save as a `.pdf` (please knit to `.pdf` if you are using `.Rmd`, or knit to `.html` and use a browser's \"Print\" function to convert to `.pdf`).\n",
    "\n",
    "If you don't like Python OR R, we will allow you to use a different language, but please turn your assignment in with: 1) a folder with all your code, 2) a folder with all your figures, and 3) a `.tex`/`.doc`/`.pdf` file with a write-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT TITLE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Describe what you are doing and why it matters to patients using at least one citation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In US, breast cancer is the second leading cause of cancer for women and it has been found that screening mammography could be incredibly helpful in terms of reducing mortality. However, this technique has been associated with a high risk of false positives as well as false negatives. Deep Learning tools have the potential to assist physicians and help patients in terms of diagnosing the patients, detecting tumor regions, as well as saving physicians' time. \n",
    "\n",
    "\n",
    "We plan to use the mammograms images along with its masks to predict tumor labels. We plan to start the project with a classic convolutional neural network to take the two images as inputs and return the diagnosis label. We will then calcualte its misclassification errors as well as AOC and ROC curves. If the model's accuracy does not match our expectations, we plan to explore other methods such as utilizing a pre-trained model. In the end, we will evaluate each model that we use and summarize the pros and cons of different training strategies. \n",
    "\n",
    "\n",
    "citation: https://www.nature.com/articles/s41598-019-48995-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Describe the relevant statistics of the data. How were the images taken? How were they labeled? What is the class balance and majority classifier accuracy? How will you divide the data into testing, training and validation sets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mammogram images are taken using X-ray and they are typically taken from 2 angles. In our case, the data are taken in both the craniocaudal and mediolateral oblique views. The two main types of breast changes found with a mammogram are calcifications and masses. The label that we used is the pathology label from the mass_case_diagnosis from the mass_case_description_train_set dataset file. The three different classes are MALIGNANT, BENIGN, and BENIGN_WITHOUT_MASK. \n",
    "\n",
    "The class MALIGNANT appeared 305 times, the class BENIGN appeared 230 times, and the class BENIGN_WITHOUT_CALLBACK appeared 40 times. The majority classifier acccuracy is 0.53. \n",
    "\n",
    "We utilized the train_test_split function from the sklearn library to divide up the dataset into testing, training and validation sets. \n",
    "\n",
    "citation: https://www.cancer.org/cancer/breast-cancer/screening-tests-and-early-detection/mammograms/mammogram-basics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Describe your data pipeline (how is the data scrubbed, normalized, stored, and fed to the model for training?).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the input data, we traversed through all the scans under the directory \"data\", stored the corresponding patient_id, side and view for each image file taken. We stored the input X as a three dimensional pixel array. Then we used the patient_id, side and view features to find the corresponding patient in the mass_Case_description_train_set dataset, and extracted their pathology result. We were able to find 575 patients that exists both in the data file and the mass_case_description dataset this way. \n",
    "\n",
    "We used the centering method to rescale the input X. We subtract the mean pixel and then divide by the standard deviation. we hope that the centering method could help us eliminate vanishing and exploding gradients, and increase convergence speed and accuracy. \n",
    "\n",
    "We used the LabelBinarizer function from sklearn library to rescale the output y. We used the one hot encoding method to convert the three output classes of y into indivator vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Explain how the model you chose works alongside the code for it. Add at least one technical citation to give credit where credit is due.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage\n",
    "import sys\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv3D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, UpSampling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras import Sequential\n",
    "import cv2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "file_root = \"data\"\n",
    "case = pd.read_csv(\"mass_case_description_train_set.csv\")\n",
    "def get_data(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    path_contents = os.walk(path)\n",
    "    for root, directories, files in path_contents: \n",
    "        for file in files:\n",
    "            if (file.split(\".\")[1] == \"h5\"):\n",
    "                path = root + '/' + file\n",
    "                h5 = h5py.File(path, 'r')\n",
    "                \n",
    "\n",
    "                patient_id = \"P_\" + root.split(\"/\")[1]\n",
    "                side = file.split(\".\")[0].split(\"_\")[0]\n",
    "                view = file.split(\".\")[0].split(\"_\")[1]\n",
    "                pathology = case[(case.patient_id == patient_id) & (case.side == side) & (case.view == view) ][\"pathology\"]\n",
    "                if (len(pathology.tolist())>0):\n",
    "                    X.append(h5['data'])\n",
    "                    pathology = pathology.tolist()[0]\n",
    "                    y.append(pathology)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def normalize_data(x, y):\n",
    "    x -= x.mean(axis=(1, 2), keepdims=True)\n",
    "    x /= x.std(axis=(1, 2), keepdims=True)\n",
    "    encoder = LabelBinarizer()\n",
    "    transformed_label = encoder.fit(np.unique(y).tolist())\n",
    "    y = transformed_label.transform(y.tolist())\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We incorporated dropout layers into our model. Dropout layers have a regularizing effect and increase generalizability to new data. Dropout layers will not include a certain amount of nodes at each training iteration, which ensures new associations can be found.\n",
    "\n",
    "Each convolutional layer in our model encodes a more abstract representation of the input images. The abstract features derived from the convolutional layers are analyzed by the Dense layers which determine which features are important for classifying tumor\n",
    "\n",
    "We got the model from this website (https://www.analyticsvidhya.com/blog/2019/04/build-first-multi-label-image-classification-model-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(256,256,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 252, 252, 16)      816       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 122, 122, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 57, 57, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,355,603\n",
      "Trainable params: 1,355,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.8223 - accuracy: 0.3530 - val_loss: 0.6472 - val_accuracy: 0.5345\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.6039 - accuracy: 0.4881 - val_loss: 0.6275 - val_accuracy: 0.5345\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.5806 - accuracy: 0.5278 - val_loss: 0.6363 - val_accuracy: 0.5345\n",
      "Epoch 4/50\n",
      "3/9 [=========>....................] - ETA: 12s - loss: 0.5793 - accuracy: 0.4974"
     ]
    }
   ],
   "source": [
    "X, y = get_data(file_root)\n",
    "X, y = normalize_data(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "\n",
    "model = model_1()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.42416191e-01, 1.08337402e-02, 6.92186952e-02],\n",
       "       [1.53840959e-01, 1.33333206e-02, 8.33658099e-01],\n",
       "       [3.91617239e-01, 2.19608545e-02, 6.04117930e-01],\n",
       "       [5.07200122e-01, 3.20895910e-01, 4.19282258e-01],\n",
       "       [4.25052345e-01, 3.51122022e-02, 5.33119678e-01],\n",
       "       [4.85127002e-01, 2.11145580e-01, 3.80196154e-01],\n",
       "       [3.07861626e-01, 5.66468537e-02, 6.86826825e-01],\n",
       "       [5.11783540e-01, 9.92894173e-04, 4.31017578e-01],\n",
       "       [2.98788607e-01, 4.78214025e-02, 7.16281056e-01],\n",
       "       [3.28314126e-01, 3.34119201e-02, 5.87500453e-01],\n",
       "       [2.81976819e-01, 2.23943293e-02, 6.22652888e-01],\n",
       "       [5.21813929e-01, 1.62944496e-02, 5.01733303e-01],\n",
       "       [4.39897269e-01, 4.44793403e-02, 5.71913779e-01],\n",
       "       [8.83205712e-01, 1.92320347e-02, 1.06046677e-01],\n",
       "       [7.12188244e-01, 2.59187818e-01, 1.54484361e-01],\n",
       "       [4.29615945e-01, 1.27773792e-01, 5.49730539e-01],\n",
       "       [4.14453655e-01, 1.84551418e-01, 5.67775905e-01],\n",
       "       [3.77051771e-01, 3.97221744e-01, 4.72875386e-01],\n",
       "       [2.02388763e-01, 6.77354038e-02, 7.20272899e-01],\n",
       "       [4.85846281e-01, 4.85221744e-02, 4.06099349e-01],\n",
       "       [3.82353842e-01, 1.90427303e-02, 5.90605617e-01],\n",
       "       [1.28288388e-01, 8.84267688e-03, 8.32391262e-01],\n",
       "       [3.36416334e-01, 1.24444962e-02, 7.03475535e-01],\n",
       "       [4.23532903e-01, 2.26965845e-02, 5.87090135e-01],\n",
       "       [5.35574079e-01, 2.01837659e-01, 3.76950711e-01],\n",
       "       [4.81497914e-01, 5.91087341e-02, 5.20681024e-01],\n",
       "       [2.80432969e-01, 1.10010803e-02, 7.15064645e-01],\n",
       "       [1.57509565e-01, 9.56961513e-03, 8.09474945e-01],\n",
       "       [1.52755350e-01, 5.13283014e-02, 8.15399289e-01],\n",
       "       [1.81139708e-01, 6.95422292e-03, 7.77823091e-01],\n",
       "       [2.27273971e-01, 2.13678181e-02, 7.40157783e-01],\n",
       "       [8.62537444e-01, 7.71701336e-03, 1.11290157e-01],\n",
       "       [7.93929815e-01, 4.77204621e-02, 1.79602116e-01],\n",
       "       [9.22611952e-01, 1.79794431e-03, 6.41049445e-02],\n",
       "       [5.93027234e-01, 2.11091042e-02, 3.84819269e-01],\n",
       "       [3.49531353e-01, 2.62201726e-02, 6.55958593e-01],\n",
       "       [2.16733247e-01, 1.16011053e-01, 7.32455790e-01],\n",
       "       [3.86055827e-01, 1.11631155e-02, 5.98440528e-01],\n",
       "       [3.50787938e-01, 3.53227258e-01, 4.83862102e-01],\n",
       "       [4.31126356e-01, 4.48843837e-03, 5.47646224e-01],\n",
       "       [1.99273616e-01, 3.93179059e-02, 7.57257581e-01],\n",
       "       [2.53420502e-01, 8.26039910e-02, 7.01166391e-01],\n",
       "       [8.69136453e-02, 4.00781631e-04, 9.27637935e-01],\n",
       "       [4.56018984e-01, 2.67290950e-01, 5.03159583e-01],\n",
       "       [3.08950484e-01, 1.27239972e-01, 6.57239020e-01],\n",
       "       [1.77071422e-01, 3.45009565e-02, 7.49255300e-01],\n",
       "       [3.88972133e-01, 2.90876597e-01, 5.39875329e-01],\n",
       "       [7.18431771e-02, 8.10965896e-03, 8.87467027e-01],\n",
       "       [4.31870699e-01, 4.39710349e-01, 4.21921909e-01],\n",
       "       [2.52819479e-01, 3.43884826e-02, 6.97655201e-01],\n",
       "       [3.58871490e-01, 1.49853230e-02, 5.87176323e-01],\n",
       "       [9.60168958e-01, 5.03167510e-03, 3.36858332e-02],\n",
       "       [2.97735333e-01, 8.34847093e-02, 6.23554468e-01],\n",
       "       [7.78693080e-01, 1.70892477e-03, 2.85351574e-01],\n",
       "       [8.61138105e-01, 3.17543745e-04, 2.20104575e-01],\n",
       "       [8.51091623e-01, 9.72315669e-03, 1.13345981e-01],\n",
       "       [3.06342244e-01, 8.92082751e-02, 6.80405140e-01],\n",
       "       [8.63773704e-01, 7.59509206e-03, 8.24858844e-02]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/hzhu04/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.08337402e-02 1.33333206e-02 2.19608545e-02 3.20895910e-01\n 3.51122022e-02 2.11145580e-01 5.66468537e-02 9.92894173e-04\n 4.78214025e-02 3.34119201e-02 2.23943293e-02 1.62944496e-02\n 4.44793403e-02 1.92320347e-02 2.59187818e-01 1.27773792e-01\n 1.84551418e-01 3.97221744e-01 6.77354038e-02 4.85221744e-02\n 1.90427303e-02 8.84267688e-03 1.24444962e-02 2.26965845e-02\n 2.01837659e-01 5.91087341e-02 1.10010803e-02 9.56961513e-03\n 5.13283014e-02 6.95422292e-03 2.13678181e-02 7.71701336e-03\n 4.77204621e-02 1.79794431e-03 2.11091042e-02 2.62201726e-02\n 1.16011053e-01 1.11631155e-02 3.53227258e-01 4.48843837e-03\n 3.93179059e-02 8.26039910e-02 4.00781631e-04 2.67290950e-01\n 1.27239972e-01 3.45009565e-02 2.90876597e-01 8.10965896e-03\n 4.39710349e-01 3.43884826e-02 1.49853230e-02 5.03167510e-03\n 8.34847093e-02 1.70892477e-03 3.17543745e-04 9.72315669e-03\n 8.92082751e-02 7.59509206e-03].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5c0dc6c701f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlr_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#ns_auc = roc_auc_score(y_test, ns_probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlr_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    548\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    549\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mnot_average_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.08337402e-02 1.33333206e-02 2.19608545e-02 3.20895910e-01\n 3.51122022e-02 2.11145580e-01 5.66468537e-02 9.92894173e-04\n 4.78214025e-02 3.34119201e-02 2.23943293e-02 1.62944496e-02\n 4.44793403e-02 1.92320347e-02 2.59187818e-01 1.27773792e-01\n 1.84551418e-01 3.97221744e-01 6.77354038e-02 4.85221744e-02\n 1.90427303e-02 8.84267688e-03 1.24444962e-02 2.26965845e-02\n 2.01837659e-01 5.91087341e-02 1.10010803e-02 9.56961513e-03\n 5.13283014e-02 6.95422292e-03 2.13678181e-02 7.71701336e-03\n 4.77204621e-02 1.79794431e-03 2.11091042e-02 2.62201726e-02\n 1.16011053e-01 1.11631155e-02 3.53227258e-01 4.48843837e-03\n 3.93179059e-02 8.26039910e-02 4.00781631e-04 2.67290950e-01\n 1.27239972e-01 3.45009565e-02 2.90876597e-01 8.10965896e-03\n 4.39710349e-01 3.43884826e-02 1.49853230e-02 5.03167510e-03\n 8.34847093e-02 1.70892477e-03 3.17543745e-04 9.72315669e-03\n 8.92082751e-02 7.59509206e-03].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_probs = model.predict_proba(X_test)\n",
    "#ns_probs = []\n",
    "lr_probs = lr_probs[:, 1]\n",
    "#ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "class_namese= [\"BENIGN\", \"MALIGNANT\", \"BENIGN_WITHOUT\"]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix( model, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE FOR QUESTION 4 HERE. USE ADDITIONAL CODE/MARKDOWN CELLS IF NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 4 HERE. USE ADDITIONAL CODE/MARKDOWN CELLS IF NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. There are many ways to do training. Take us through how you do it (e.g. \"We used early stopping and stopped when validation loss increased twice in a row.\").**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train our model, we use 50 training epochs. Moreover, we split the data into a train set (66%) and a test set (33%) to ensure our evaluation is not susceptible to overfitting and is representative of new input. This training and evaluation procedure allowed our model to have success in learnign how to predict tumors and also a fair evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Make a figure displaying your results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE FOR QUESTION 6 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN ANSWER TO QUESTION 6 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Discuss pros and cons of your method and what you might have done differently now that you've tried or would try if you had more time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main pro of our methodology is that we are using a deep learning network that is quite powerful and should be able to extract all the features pertinent to tumor identification. Moreover, we are using classically succesful pre-processing techniques like normalization, and regularization techniques like dropout layers. This general procedure has been effective in other similar tasks and so we think this is a reasonable strategy. This is shown by our relatively succesful accuracy of X %.\n",
    "\n",
    "Cons: Our dataset is too small for this neural network. \n",
    "\n",
    "There are several areas that we can improve on. First, our model is not comprehensively tuned, and it would be beneficial to test more hyper-parameters such as batch sizes, epochs, optimizer, number of layers, etc.... Our model also has a rather modest data set with 175 patients. In order to achieve state-of-the-art results, a dataset that is far larger would be required. While normalizing is a good first step for pre-processing, we could also apply other techniques such as gaussian smoothing, data augmentation, and housfield unit conversion. Using pre-trained networks is also a strategy that has shown classical success that we did not try. In general, it seems as though our strategy is good, but would benefit from more trial-and-error with equally good ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will not be graded on the performance of your model. You'll only be graded on the scientific soundness of your claims, methodology, evaluation (i.e. fair but insightful statistics), and discussion of the strengths and shortcomings of what you tried. Feel free to reuse some of the code you are/will be using for your projects. The write-up doesn't need to be long (~1 page will suffice), but please cite at least one clinical paper and one technical paper (1 each in questions 1 and 4 at least, and more if needed).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
